# CUDA_VISIBLE_DEVICES='0, 1' python -u main.py \
#     --model_type='lxmert'\
#     --savedmodel_path='save/lxmert_roberta_base_fd6_fh12/fgm_ema_mask_sl_384_lr5e-5/' \
#     --ckpt_file='lxmert_best_mean_f1' \
#     --final_ckpt_file='lxmert_final' \
#     --learning_rate=5e-5 \
#     --bert_seq_length=384 \
#     --bert_dir='hfl/chinese-roberta-wwm-ext' \
#     --bert_tokenizer_dir='hfl/chinese-roberta-wwm-ext' \
#     --fusion_num_hidden_layers=6 \
#     --fusion_num_attention_heads=12 \
#     --val_ratio=0.2 \
    
CUDA_VISIBLE_DEVICES='0, 1' python -u main.py \
    --model_type='albef' \
    --savedmodel_path='save/albef_roberta_base/fgm_ema_mask_sl_384_lr5e-5/' \
    --ckpt_file='albef_best_mean_f1' \
    --final_ckpt_file='albef_final' \
    --learning_rate=5e-5 \
    --bert_seq_length=384 \
    --bert_dir='hfl/chinese-roberta-wwm-ext' \
    --bert_tokenizer_dir='hfl/chinese-roberta-wwm-ext' \
    --val_ratio=0.2 \